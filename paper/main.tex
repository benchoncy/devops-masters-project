\documentclass[12pt]{article}

% Set up data, if you need to add a package, go here
\input{setup/packages.tex}

\begin{document}


\thispagestyle{empty}
\setlength\headheight{0pt} 
\begin{center}

\begin{center}
\includegraphics[width=0.65\linewidth]{images/TUD_Logo.png}            
\end{center}	

        \vspace{0.25cm}
        {\scshape\LARGE TU Dublin, Tallaght Campus \par}
        \vspace{0.25cm}
        {\scshape\Large MSc DevOps Research Project\par}
        \vspace{0.5cm}

        {\Large\bfseries MLOps workflow tools comparision\par}
        
        \vspace{0.5cm}
        {\Large\itshape Ben Stuart\par}
        Department of Computing
        \vspace{0.25cm}

\vspace{1cm}
Supervised by\par
Dr. Jelena Vasic\\
Department of Computing\par
\vspace{1.5cm}
\large
\today

\end{center}

\clearpage
\restoregeometry
\justify

\section*{Declaration}
I hereby certify that the material, which I now submit for assessment on the programmes of study leading to the award of Master of Science, is entirely my own work and has not been taken from the work of others except to the extent that such work has been cited and acknowledged within the text of my own work. No portion of the work contained in this thesis has been submitted in support of an application for another degree or qualification to this or any other institution.

\vspace{2cm}
\begin{flushright}
-----------------------------------\\
Ben Stuart\\
\today
\end{flushright}
\pagebreak

\section*{Acknowledgements}
Personal acknowledgements and/or dedications may be included by the candidate directly after the declaration page. Where possible these should be kept to one page and be of a tone appropriate to a higher degree.
\pagebreak

%List of figures and tables, automatic from thesis.
\listoffigures
\pagebreak
 
\listoftables
\pagebreak


\tableofcontents
\pagebreak

\section*{Abstract}
This research project aims to analyse and compare tools and approaches to constructing and orchestrating machine learning workflow pipelines. These pipelines are often used for continuous training and other machine-learning tasks in an MLOps context to automate and orchestrate model training and delivery and simplify experimentation and troubleshooting. The proposed paper will focus on Metaflow, Apache Airflow and SageMaker pipelines tools and the techniques they employ to build and orchestrate pipelines in AWS.
\pagebreak

\section{Introduction}
\subsection{Subsection Example}
I am a subsection
\subsubsection{Sub Subsection Example}
I am a sub subsection
\pagebreak

\section{Literature Review}
DevOps is a set of principles and practices aimed at improving the lifecycle of software applications and bridging the gap between IT operations and software development teams. DevOps as a practice leads to higher velocity, more automation and faster feedback \citep{kimPhoenixProjectNovel2018, kimDevOpsHandbookHow2016, humbleContinuousDeliveryReliable2010, kreuzbergerMachineLearningOperations2022}

Machine Learning refers to the application of learning algorithms on specific datasets. The resulting model can then be used to take input and infer new data based on data previously seen. Common applications of machine learning include recommendation systems, future prediction, classification and content generation. The typical producer and users of machine learning are Data Scientists, Analysts or ML Engineers using the resulting models for internal use, research or building client-facing applications. \citep{polyzotisDataManagementChallenges2017, helmMachineLearningArtificial2020}

Machine Learning Operation (MLOps) is the application of DevOps principles and practices to Machine Learning (ML) \citep{kreuzbergerMachineLearningOperations2022, shankarOperationalizingMachineLearning2022, zhouMLOpsCaseStudy2020}. A concrete consensus on the definition of MLOps is still unresolved; many ML studies are focused on the performance and building of models. MLOps brings an opportunity to focus on productionising and operating ML and its lifecycle as others have achieved in software development with DevOps \citep{kreuzbergerMachineLearningOperations2022, shankarOperationalizingMachineLearning2022}. Recent studies have shown increased interest in operating ML, infrastructure, and rapid deployment of ML in the community \citep{makinenWhoNeedsMLOps2021}.

One common practice of MLOps includes \textit{Continous Trainng} (CT); similar to Continous Integration and Continous Deployment (CD/CD), Continous training is the practice of building the required steps to train a model into a pipeline that can be run on a dedicated server to be automated, repeatable and democratised so that models can be trained and re-trained on-demand, on-schedule or on a trigger \citep{humbleContinuousDeliveryReliable2010, kimPhoenixProjectNovel2018, googleMLOpsContinuousDelivery2023, giftPracticalMLOpsOperationalizing2021, zhouMLOpsCaseStudy2020}.

Continuous Training pipelines are often written as \textit{Machine Learning pipelines} (MLP), sometimes referred to as \textit{ML workflow pipelines}. These pipelines are written as discrete interdependent steps, forming a directed acyclical graph (DAG) \citep{muiruriPracticesInfrastructuresMachine2022, zhouMLOpsCaseStudy2020}. ML tasks may often require large amounts of computing resources \citep{tuulosEffectiveDataScience2022, muiruriPracticesInfrastructuresMachine2022}. Writing workflows in this way allows these workflows to be orchestrated on distributed systems, re-run steps independently, and utilise available compute resources efficiently \citep{fowlerContinuousDeliveryMachine2019, muiruriPracticesInfrastructuresMachine2022}.

MLPs are used to perform general ML tasks, including continuous training, feature engineering or periodic model evaluations, especially where tasks require long-running jobs, large amounts of compute or automated orchestration \citep{shankarOperationalizingMachineLearning2022, tuulosEffectiveDataScience2022, kreuzbergerMachineLearningOperations2022}. Several MLP frameworks, libraries and services appear in the literature (Kubeflow pipelines, Metaflow, TensorFlow Extended (TFX), AWS SageMaker pipelines, Apache Airflow, Prefect, Luigi). These tools often have some common characteristics and methods, such as constructing DAG objects using a library or framework, encapsulating steps in containers, storing run metadata and translating these DAGs onto battle-tested orchestration platforms such as Argo Workflows, AWS Batch or Apache Airflow \citep{tagliabueReasonableScaleMachine2023, tuulosEffectiveDataScience2022, muiruriPracticesInfrastructuresMachine2022}. These tools best practices and features are rarely discussed in the current literature, leaving a gap where no consensus has been formed regarding individual features and methods' benefits or drawbacks for ML workflows.
\pagebreak

\section{Methodology}
\pagebreak

\section{Results}
\pagebreak

\section{Discussion}
\pagebreak

\section{Conclusions}
\pagebreak

\section{Appendices}
\pagebreak

%prints bibliography from bibliography file.
\printbibliography

\end{document}
